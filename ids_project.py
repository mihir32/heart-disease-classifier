# -*- coding: utf-8 -*-
"""IDS_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18lWEXchTgEOBEGr-dk0zXnjg2miVZ3ET

# Heart Disease Classification

# Importing Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
import plotly as py
import plotly.graph_objs as go
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score,confusion_matrix, f1_score
from sklearn import svm
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import train_test_split


# Initializations
init_notebook_mode(connected=True)

# Remove any warning messages
warnings.filterwarnings("ignore")

"""# Reading Data Set"""

datafr = pd.read_csv("heart.csv", error_bad_lines=False)

"""# Structure of Data Set"""

display(datafr.head(10))

# Dimension of the datatset
print("Dimension of the dataset is: ",datafr.shape)
# Check if any column has missing value
datafr.isnull().sum()

"""# Observation for Target Variable"""

len(datafr.target[datafr.target==0])

len(datafr.target[datafr.target==1])

"""They are roughly the same so we can use ROC curve as it summarize the trade-off between the true positive rate and false positive rate for a predictive model using different probability thresholds.

# Replacing Labels
"""

cleanup_nums = {"cp":     {0: "CPType 0", 1: "CPType 1", 2:"CPType 2", 3: "CPType 3"},
                "thal": {0: "Normal", 1: "Fixed Defect", 2: "Reversable Defect" }}
datafr.replace(cleanup_nums, inplace=True)
datafr.head()

"""# Graphical Represetation"""

male =len(datafr[datafr['sex'] == 1])
female = len(datafr[datafr['sex']== 0])

# Data to plot
labels = 'Male','Female'
sizes = [male,female]

# Plot
plt.figure(figsize=(6,6))
plt.pie(sizes, explode=(0, 0.1), labels=labels, colors=sns.color_palette("Blues"),
autopct='%1.1f%%', shadow=True, startangle=90)
plt.title('Pie Chart Ratio for Sex Distribution\n', fontsize=16)
sns.set_context("paper", font_scale=1.2)

f, axes = plt.subplots(1, 3, sharey=True, figsize=(15, 8))
sns.boxplot(x="sex", y="trestbps", hue="target", data=datafr, palette='Blues', ax=axes[0])
axes[0].set_title('BoxPlot for {}'.format("trestbps"))
sns.boxplot(x="sex", y="thalach", hue="target", data=datafr, palette='Purples', ax=axes[1])
axes[1].set_title('BoxPlot for {}'.format("thalach"))
sns.boxplot(x="sex", y="chol", hue="target", data=datafr, palette='Oranges', ax=axes[2])
axes[2].set_title('BoxPlot for {}'.format("chol"))

"""Plot displaying male and female with potential heart disease based on age"""

plt.figure(figsize=(6,6))
sns.catplot(x="sex", y="age", hue="target", kind="swarm", data=datafr, palette='Greens')
plt.title('Swarm Plot of Sex vs Age\n', fontsize=16)
sns.set_context("paper", font_scale=1.2)

"""Visualizing the ratio of different chest pain types in the dataset"""

# Data to plot
labels = 'Chest Pain Type:0','Chest Pain Type:1','Chest Pain Type:2','Chest Pain Type:3'
sizes = [len(datafr[datafr['cp'] == "CPType 0"]),len(datafr[datafr['cp'] == "CPType 1"]),
         len(datafr[datafr['cp'] == "CPType 2"]),
         len(datafr[datafr['cp'] == "CPType 3"])]

plt.figure(figsize=(6,6))

# Plot
plt.pie(sizes, explode=(0.05, 0.05, 0.05, 0.05), labels=labels, colors=sns.color_palette("Reds"),
autopct='%1.1f%%', shadow=True, startangle=90)
plt.title('Pie Chart Ratio for type of Chest Pain\n', fontsize=16)
sns.set_context("paper", font_scale=1.2)

plt.axis('equal')
plt.show()

"""Plot displaying potential of heart disease based on various levels of chest pain types by age"""

plt.figure(figsize=(6,6))
sns.catplot(x="cp", y="age", hue="target", kind="swarm", data=datafr, palette='Greens')
plt.title('Swarm Plot of CP vs Age\n', fontsize=16)
sns.set_context("paper", font_scale=1.2)

"""
Normalizing the values and then making it as a DataFrame and then plotting using sns.barplot.
"""
plt.figure(figsize=(6,6))
temp = (datafr.groupby(['target']))['cp'].value_counts(normalize=True)\
.mul(100).reset_index(name = "percentage")
sns.barplot(x = "cp", y = "percentage", hue = "target", data = temp, palette='Blues')\
.set_title("Chest Pain vs Heart Disease\n", fontsize=16)
sns.set_context("paper", font_scale=1.2)

"""Visualizing the ratio of dataset based on (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)"""

# Data to plot
labels = 'fasting blood sugar < 120 mg/dl','fasting blood sugar > 120 mg/dl'
sizes = [len(datafr[datafr['fbs'] == 0]),len(datafr[datafr['cp'] == "CPType 1"])]

plt.figure(figsize=(6,6))
 
# Plot
plt.pie(sizes, explode=(0.05, 0.05), labels=labels, colors=sns.color_palette("Blues"),
autopct='%1.1f%%', shadow=True, startangle=90)
plt.title('Pie Chart Ratio for Fasting Blood Sugar\n', fontsize=16)
sns.set_context("paper", font_scale=1.2)
 
plt.axis('equal')
plt.show()

"""Checking the distribution of feature 'thalach: maximum heart rate achieved'"""

sns.set(style="darkgrid")
plt.figure(figsize=(12,6))
sns.distplot(datafr['thalach'],kde=False,bins=30,color='steelblue')
plt.title('Distribution of Thalach\n', fontsize=16)
sns.set_context("paper", font_scale=1.4)

"""The distribution is normal indicating most population fall between 140-180 with some left tail indicating few outliers which we can validate once we create a scatterplot with residuals, leverage and cook's distance.

Checking the distribution of feature 'chol: serum cholestoral in mg/dl'
"""

sns.set(style="darkgrid")
plt.figure(figsize=(12,6))
sns.distplot(datafr['chol'],kde=False,bins=30,color="green")
plt.title('Distribution of Chol\n', fontsize=16)
sns.set_context("paper", font_scale=1.4)

"""Visualizing the distribution of people having heart disease based on age"""

plt.figure(figsize=(15,6))
sns.countplot(x='age',data = datafr, hue = 'target',palette='GnBu')
sns.set_context("paper", font_scale=1.4)
plt.show()

"""# Data Preparation"""

datafr = pd.get_dummies(datafr, columns=["cp", "thal"])
datafr.head()

"""Splitting Dataset into Test and Train"""

# Predictor variables
X= datafr.drop('target',axis=1)
# Target or Class variable
Y=datafr['target']

# Let's using scikit learn to split our dataset
# Using 70:30 ratio for train:test
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=.3,random_state=400)

X_train.shape

X_test.shape

"""# Preprocessing and Cleaning"""

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_train = pd.DataFrame(X_train_scaled)

X_test_scaled = scaler.transform(X_test)
X_test = pd.DataFrame(X_test_scaled)

"""# Modeling"""

# Using 10 folds cross-validation
def CrossVal(trainX,trainY,model):
    accuracy=cross_val_score(model,trainX , trainY, cv=10, scoring='accuracy')
    return(accuracy)

"""# Applying ML Algorithms

# Simple Vector Machine
"""

# Start with Support Vector Machine for Binary Classification
clf = svm.SVC(gamma='scale', probability=True)
# Creare a model with X_train and Y_train data
clf.fit(X_train,Y_train)
# predict probabilities
probs = clf.predict_proba(X_test)
# keep probabilities for the positive outcome only
probs = probs[:, 1]

# Run the model on X_test to predict the target labels. 
predict1 = clf.predict(X_test)
clf=svm.SVC(C=0.2,probability=True,kernel='rbf',gamma='scale')
score_clf=CrossVal(X_train,Y_train,clf)
print("Cross-Validation accuracy is {:.2f}%".format(score_clf.mean()*100))

# Compare the predicted target labels with Y_test
print("Test Accuracy using SVM Model: {:.2f}%".format(accuracy_score(Y_test,predict1)*100))
# assign cnf_matrix with result of confusion_matrix array
cnf_matrix = confusion_matrix(Y_test,predict1)

# calculate AUC
auc_svm = roc_auc_score(Y_test, probs)
#print('AUC: %.3f' % auc)
# calculate roc curve
fpr, tpr, thresholds = roc_curve(Y_test, probs)
# plot no skill
plt.plot([0, 1], [0, 1], linestyle='--')
# plot the roc curve for the model
plt.plot(fpr, tpr, marker='.')
plt.title("ROC Curve for SVM with AUC Score: {:.3f}".format(auc_svm))
# show the plot
plt.show()

#create a heat map
sns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Purples', fmt = 'd')
svm_f1=f1_score(Y_test,predict1)
plt.title('F1 Score for SVM model is {:.2f}'.format(svm_f1))

"""# Random Forest Classifier"""

rf = RandomForestClassifier(n_estimators = 13,random_state = 40)
# Creare a model with X_train and Y_train data
rf.fit(X_train,Y_train)
# predict probabilities
probs = rf.predict_proba(X_test)
# keep probabilities for the positive outcome only
probs = probs[:, 1]

predict2 = rf.predict(X_test)
rf=RandomForestClassifier(n_estimators=13, n_jobs=-1, random_state=40)
score_rf= CrossVal(X_train,Y_train,rf)
print('Cross-Validation accuracy is {:.2f}%'.format(score_rf.mean()*100))

print("Accuracy using Random Forest Model: {:.2f}%".format(accuracy_score(Y_test,predict2)*100))
# assign cnf_matrix with result of confusion_matrix array
cnf_matrix = confusion_matrix(Y_test,predict2)

# calculate AUC
auc_rf = roc_auc_score(Y_test, probs)
#print('AUC: %.3f' % auc)
# calculate roc curve
fpr, tpr, thresholds = roc_curve(Y_test, probs)
# plot no skill
plt.plot([0, 1], [0, 1], linestyle='--')
# plot the roc curve for the model
plt.plot(fpr, tpr, marker='.')
plt.title("ROC Curve for Random Forest with AUC Score: {:.3f}".format(auc_rf))
# show the plot
plt.show()

#create a heat map
sns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Purples', fmt = 'd')
rf_f1=f1_score(Y_test,predict2)
plt.title('F1 Score for Random Forest model is {:.2f}'.format(rf_f1))

"""# KNN Classifier"""

error = []

# Calculating error for K values between 1 and 30
for i in range(1, 30):  
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(X_train, Y_train)
    pred_i = knn.predict(X_test)
    error.append(np.mean(pred_i != Y_test))

plt.figure(figsize=(12, 6))  
plt.plot(range(1, 30), error, color='red', linestyle='dashed', marker='o',  
         markerfacecolor='blue', markersize=10)
plt.title('Error Rate K Value')  
plt.xlabel('K Value')  
plt.ylabel('Mean Error')

"""From the above figure we can see that we get a minimum error when k is 12."""

knn=KNeighborsClassifier(algorithm='auto',n_neighbors= 12)
# Creare a model with X_train and Y_train data
knn.fit(X_train,Y_train)
# predict probabilities
probs = knn.predict_proba(X_test)
# keep probabilities for the positive outcome only
probs = probs[:, 1]

predict4 = knn.predict(X_test)
score_knn= CrossVal(X_train,Y_train,knn)
print('Cross-Validation accuracy is {:.2f}%'.format(score_knn.mean()*100))

print("Accuracy using K Nearest Neighbours Model: {:.2f}%".format(accuracy_score(Y_test,predict4)*100))
# assign cnf_matrix with result of confusion_matrix array
cnf_matrix = confusion_matrix(Y_test,predict4)

# calculate AUC
auc_knn = roc_auc_score(Y_test, probs)
#print('AUC: %.3f' % auc)
# calculate roc curve
fpr, tpr, thresholds = roc_curve(Y_test, probs)
# plot no skill
plt.plot([0, 1], [0, 1], linestyle='--')
# plot the roc curve for the model
plt.plot(fpr, tpr, marker='.')
plt.title("ROC Curve for KNN with AUC Score: {:.3f}".format(auc_knn))
# show the plot
plt.show()

#create a heat map
sns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Purples', fmt = 'd')
knn_f1=f1_score(Y_test,predict4)
plt.title('F1 Score for K Nearest Neighbour model is {:.2f}'.format(knn_f1))

"""# AdaBoost Classifier"""

# Using Random Forest model 'rf' for boosting
ada=AdaBoostClassifier(rf,n_estimators=100, random_state=40, learning_rate=0.1)
# Creare a model with X_train and Y_train data
ada.fit(X_train,Y_train)
# predict probabilities
probs = ada.predict_proba(X_test)
# keep probabilities for the positive outcome only
probs = probs[:, 1]

predict5 = ada.predict(X_test)
score_ada= CrossVal(X_train,Y_train,ada)
print('Cross-Validation accuracy is {:.2f}%'.format(score_ada.mean()*100))

print("Accuracy using AdaBoost Model: {:.2f}%".format(accuracy_score(Y_test,predict5)*100))
# assign cnf_matrix with result of confusion_matrix array
cnf_matrix = confusion_matrix(Y_test,predict5)

# calculate AUC
auc_ada = roc_auc_score(Y_test, probs)
#print('AUC: %.3f' % auc)
# calculate roc curve
fpr, tpr, thresholds = roc_curve(Y_test, probs)
# plot no skill
plt.plot([0, 1], [0, 1], linestyle='--')
# plot the roc curve for the model
plt.plot(fpr, tpr, marker='.')
plt.title("ROC Curve for AdaBoost with AUC score: {:.3f}".format(auc_ada))
# show the plot
plt.show()

#create a heat map
sns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Purples', fmt = 'd')
ada_f1=f1_score(Y_test,predict5)
plt.title('F1 Score for AdaBoost model is {:.2f}'.format(ada_f1))

"""# Conclusion"""

cv_svm = score_clf.mean()*100
cv_rf = score_rf.mean()*100
cv_knn = score_knn.mean()*100
cv_ada = score_ada.mean()*100
# Cross Validation Accuracy list for all models
cv = [cv_svm, cv_rf, cv_knn, cv_ada]
# F1 Score list for all models
f1 = [svm_f1, rf_f1, knn_f1, ada_f1]
# AUC Score list for all models
auc = [auc_svm, auc_rf, auc_knn, auc_ada]
# Name List of ML Models used
models = ['SVM', 'Random Forest', 'KNN', 'AdaBoost']
y_pos = np.arange(len(models)) #Position = 0,1,2,3,4

# Plot Cross Validation Accuracy
plt.figure(figsize=(10, 6))  
plt.bar(y_pos, cv, align='center', alpha=0.8, color=sns.color_palette("PuRd"))
plt.xticks(y_pos, models)
plt.ylabel('Cross Validated Accuracy')
plt.title('Performance based on CV Accuracy')

# Plot F1 Score
plt.figure(figsize=(10, 6))  
plt.bar(y_pos, f1, align='center', alpha=0.8, color=sns.color_palette("RdPu"))
plt.xticks(y_pos, models)
plt.ylabel('F1 Score')
plt.title('Performance based on F1 Score')

# Plot AUC Score
plt.figure(figsize=(10, 6))  
plt.bar(y_pos, auc, align='center', alpha=0.8, color=sns.color_palette("BuPu"))
plt.xticks(y_pos, models)
plt.ylabel('AUC Score')
plt.title('Performance based on AUC Score')

"""Based on the above two comparison plots: Cross-Validated Accuracy and F1 Score, K Nearest Neighbours (KNN) seems to have an ideal balance between underfitting and overfitting along with a high F1 Score. KNN also outperforms the competition with the highest test accuracy and highest AUC Score."""